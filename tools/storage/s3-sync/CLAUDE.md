# S3 Bucket Synchronization Tool - OpsKit Version

## 功能描述
S3存储桶同步工具，提供安全、交互式的存储桶到存储桶同步操作，支持AWS S3和自定义S3兼容端点。

## 技术架构
- 实现语言: Python 3.7+
- 核心依赖: boto3 (AWS SDK), botocore (底层AWS服务)
- 系统要求: Python 3.7+ 环境
- OpsKit 集成: 使用 OpsKit 环境变量和缓存目录管理

## 配置项

### OpsKit 环境变量
工具使用以下 OpsKit 内置环境变量：

- **OPSKIT_TOOL_TEMP_DIR**: 工具临时文件夹，用于写入连接缓存和配置文件
- **OPSKIT_BASE_PATH**: OpsKit 的目录路径
- **OPSKIT_WORKING_DIR**: 用户终端当前所在目录
- **TOOL_NAME**: 工具名称（s3-sync）
- **TOOL_VERSION**: 工具版本号

### 缓存文件结构
```
${OPSKIT_TOOL_TEMP_DIR}/
├── connections.json    # 缓存的S3连接信息（密钥已加密）
```

## 开发指南

### 核心架构
- **S3SyncTool 类**: 单文件架构，包含所有功能
- **配置管理**: 配置存储在 `OPSKIT_TOOL_TEMP_DIR` 目录
- **连接缓存**: 连接信息缓存在 `connections.json`（包含 base64 编码的密钥）
- **命名连接**: 便于识别和重用的连接名称
- **控制台日志**: 所有信息直接输出到控制台，无文件日志

### 安全模型
- 密钥通过 `getpass` 收集（隐藏输入）
- 密钥使用简单 base64 编码存储（非安全加密）
- 缓存前进行连接验证
- 破坏性操作需要用户输入 'YES' 确认

### 同步流程
1. 交互式连接输入，支持自定义名称（源 → 目标）
2. 连接测试和缓存，密钥加密存储
3. 存储桶内省，选择源存储桶
4. 确认同步操作，包含同步统计信息
5. 并行复制对象，支持重试机制
6. 综合成功/失败报告

### 关键功能实现

**连接缓存策略**
- 用户定义标识符的命名连接
- 文件缓存包含 base64 编码的密钥以便使用
- 无需密钥提示即可自动重用缓存连接

**存储桶选择**
- 使用 `list_buckets()` 列出可用存储桶
- 交互式多选支持：单个 (3)、多个 (1,3,5)、范围 (1-5) 或全部
- 支持在任何时候 Ctrl+C 取消选择

**并行处理**
- 使用 `ThreadPoolExecutor` 进行并发对象复制
- 可配置的工作线程数（默认10个）
- 重试机制：失败时最多重试 5 次，包含指数退避
- 进度追踪：每100个对象显示进度

**错误处理策略**
- 各阶段键盘中断处理
- 启动时验证依赖包可用性
- 优雅处理部分失败情况
- 详细的错误信息和重试日志

**安全特性**
- 操作前连接测试
- 自动创建目标存储桶（如果不存在）
- 同步操作确认，包含详细配置信息
- 需要明确的 'YES' 确认才能开始同步
- 个别对象同步状态跟踪和报告

## 连接配置

### AWS S3 (默认)
- 留空端点URL使用AWS S3
- 提供默认AWS区域支持
- 使用默认AWS凭证链

### 自定义S3端点
- 输入有效的http/https URL用于非AWS S3提供商
- 支持MinIO、DigitalOcean Spaces和其他S3兼容服务
- 验证端点URL格式

## 使用示例

### 基本使用流程
```bash
# 通过 OpsKit 运行工具
opskit run s3-sync

# 工具将引导您完成以下步骤：
# 1. 配置源S3连接（或选择已缓存的连接）
# 2. 选择要同步的源存储桶
# 3. 配置目标S3连接（或选择已缓存的连接）
# 4. 确认同步操作
# 5. 执行并行同步
```

### 连接缓存使用
- 首次使用时输入连接信息，工具会自动缓存
- 后续使用可直接选择已缓存的连接
- 支持为每个连接设置自定义名称便于识别

### 存储桶选择模式
- 单个选择：输入编号（如：3）
- 多个选择：用逗号分隔（如：1,3,5）
- 范围选择：使用连字符（如：1-5）
- 全部选择：输入 'all'

### 并行处理配置
```bash
# 使用默认10个工作线程
opskit run s3-sync

# 使用自定义工作线程数
python main.py --workers 20
```

### 安全确认
- 同步前会显示详细的操作信息
- 必须输入 'YES'（大写）才能继续
- 任何时候都可以使用 Ctrl+C 取消操作

## 连接类型支持

### AWS S3 到 AWS S3
- 留空端点
- 使用AWS凭证或默认配置文件

### MinIO 到 DigitalOcean Spaces
- 输入MinIO端点：`http://localhost:9000`
- 输入DigitalOcean端点：`https://nyc3.digitaloceanspaces.com`

## 并行处理和特性

### 并发控制
- **全局并发**: 通过 `--workers` 参数设置或 `max_workers` 参数
- **默认**: 10个并发工作线程
- **范围**: 1-50个工作线程（根据网络和系统容量调整）
- **CLI用法**: `python main.py --workers 20`

### 重试机制
- **自动重试**: 对失败的对象复制重试5次
- **指数退避**: 重试间隔为 2^n 秒 (2, 4, 8, 16, 32)
- **错误日志**: 在日志中记录详细的重试信息
- **成功确认**: 报告成功的重试

### 增强日志
- **控制台输出**: 彩色编码的控制台输出用于不同级别
- **进度跟踪**: 每100个对象报告一次进度
- **详细摘要**: 按存储桶和总计的同步统计
- **格式化输出**: 匹配mysql-sync风格的分隔符

## 系统要求
- Python 3.7+ 环境
- boto3 Python包
- botocore Python包
- OpsKit 环境（提供必要的环境变量）

## 故障排除

### 常见问题
1. **缺少依赖**: 需要安装 boto3 包
2. **连接失败**: 检查网络连接和凭证
3. **权限不足**: 确保AWS用户有足够的权限执行S3操作
4. **缓存文件损坏**: 删除 `connections.json` 文件重新创建连接

### 性能优化
- 大型存储桶同步可能需要较长时间
- 网络不稳定时建议减少工作线程数
- 重试机制会在失败时自动重试，最多 5 次

## 限制

- 默认并发上传限制是10个文件
- 可通过 `max_workers` 参数配置
- 高并发可能增加网络和内存使用
- 需要完整对象下载和上传
- 无部分同步或选择性对象传输